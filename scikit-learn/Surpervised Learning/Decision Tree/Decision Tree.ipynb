{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**决策树（DT）**是用于分类和回归的非参数监督学习方法。目标是创建一个模型，通过学习从数据特征推断出的简单决策规则来预测目标变量的价值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树的一些优点是：\n",
    "+ 很容易理解和解释。树可以被可视化。\n",
    "+ 只需很少的数据准备。其他技术通常需要数据标准化，需要创建虚拟变量并删除空白值。但请注意，此模块不支持缺少的值。\n",
    "+ 使用树的成本（即预测数据）是用于训练树的数据点的数量的对数。\n",
    "+ 能够处理数字和分类数据。其他技术通常专门用于分析只有一种类型变量的数据集。查看更多信息的算法。\n",
    "+ 能够处理多输出问题。\n",
    "+ 使用白盒模型。如果给定的情况在模型中是可观察的，则条件的解释很容易通过布尔逻辑来解释。相比之下，在黑盒模型（例如，在人工神经网络中），结果可能更难以解释。\n",
    "+ 可以使用统计测试来验证模型。这可以说明模型的可靠性。\n",
    "+ 即使其假设受到数据生成的真实模型的某种程度的干扰，也可以很好地执行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树的缺点包括：\n",
    "+ 决策树学习者可以创建过于复杂的树，不能很好地概括数据。这被称为过度拟合。修剪（目前不支持）等机制，设置叶节点所需的最小样本数或设置树的最大深度是避免此问题所必需的。\n",
    "+ 决策树可能不稳定，因为数据中的小变化可能会导致生成完全不同的树。通过在集合中使用决策树可以缓解这个问题。\n",
    "+ 学习最优决策树的问题在最优化的几个方面甚至简单的概念下已知是NP完全的。因此，实际决策树学习算法基于启发式算法，例如在每个节点进行局部最优决策的贪婪算法。这样的算法不能保证返回全局最优决策树。这可以通过在集合学习器中训练多棵树来缓解，其中特征和样本随机地用替换采样。\n",
    "+ 有些概念很难学，因为决策树不能很容易地表达它们，例如XOR，奇偶校验或多路复用器问题。\n",
    "+ 如果某些类占主导地位，决策树学习者会创建偏向性树。因此，建议在拟合决策树之前平衡数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10.1. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "X = [[0,0],[1,1]]\n",
    "y = [0,1]\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过拟合后，该模型可用于预测样本的类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[2.,2.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或者，可以预测每个类的概率，这是叶中同一类的训练样本的分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba([[2.,2.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier能够同时具有二元（其中标签是[-1,1]）分类和多类别（其中标签是[0，...，K-1]）分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "iris = datasets.load_iris()\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import graphviz\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None)\n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "\n",
    "graph.render('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(iris.data[:1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(iris.data[:1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10.2.Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "X = [[0,0],[2,2]]\n",
    "y = [0.5, 2.5]\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[1,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10.3. Multi-output problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With regard to decision trees, this strategy can readily be used to support multi-output problems. This requires the following changes:\n",
    "+ Store n output values in leaves, instead of 1;\n",
    "+ Use splitting criteria that compute the average reduction across all n outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module offers support for multi-output problems by implementing this strategy in both DecisionTreeClassifier and DecisionTreeRegressor. If a decision tree is fit on an output array Y of size [n_samples, n_outputs] then the resulting estimator will:\n",
    "\n",
    "+ Output n_output values upon predict;\n",
    "+ Output a list of n_output arrays of class probabilities upon predict_proba.\n",
    "\n",
    "The use of multi-output trees for regression is demonstrated in Multi-output Decision Tree Regression. In this example, the input X is a single real value and the outputs Y are the sine and cosine of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
